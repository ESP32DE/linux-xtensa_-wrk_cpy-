/*
 * arch/xtensa/include/asm/core.h
 *
 * Xtensa macros for MMU V3 Support. Deals with re-mapping the Virtual
 * Memory Addresses from "Virtual == Physical" to their prevvious V2 MMU
 * mappings (KSEG at 0xD0000000 and KIO at 0XF0000000). 
 *
 * This file is subject to the terms and conditions of the GNU General Public
 * License.  See the file "COPYING" in the main directory of this archive
 * for more details.
 *
 * Copyright (C) 2008 - 2009 Tensilica Inc.
 *
 * Pete Delaney <piet@tensilica.com>
 * Marc Gauthier <marc@tensilica.com
 */

#ifndef _XTENSA_ASM_CORE_H
#define _XTENSA_ASM_CORE_H


#if defined(XCHAL_HAVE_PTP_MMU) && XCHAL_HAVE_PTP_MMU && XCHAL_HAVE_SPANNING_WAY  
/* MMU v3 */
#define PHYSICAL_MEMORY_ADDRESS 0x00000000
#define VIRTUAL_MEMORY_ADDRESS  0xD0000000	/* Will Become VECBASE */
#define KERNELOFFSET 		0xD0001000  	/* Image Virtual Start Address */
#define LOAD_MEMORY_ADDRESS  	0x00001000
#define XC_VADDR(offset)	(VIRTUAL_MEMORY_ADDRESS  + offset)
#define XC_PADDR(offset)	(PHYSICAL_MEMORY_ADDRESS + offset)

#undef  XCHAL_VECBASE_RESET_VADDR
#define XCHAL_VECBASE_RESET_VADDR	VIRTUAL_MEMORY_ADDRESS

#define XCHAL_RESET_VECTOR0_VECOFS	(XCHAL_RESET_VECTOR0_VADDR - XCHAL_VECBASE_RESET_VADDR)
#undef  XCHAL_RESET_VECTOR0_VADDR
#define XCHAL_RESET_VECTOR0_VADDR	XC_VADDR(XCHAL_RESET_VECTOR1_VECOFS);

#define XCHAL_RESET_VECTOR1_VECOFS	(XCHAL_RESET_VECTOR1_VADDR - XCHAL_VECBASE_RESET_VADDR)
#undef  XCHAL_RESET_VECTOR1_VADDR
#define XCHAL_RESET_VECTOR1_VADDR	XC_VADDR(XCHAL_RESET_VECTOR1_VECOFS);

#undef  XCHAL_USER_VECTOR_VADDR
#define XCHAL_USER_VECTOR_VADDR		XC_VADDR(XCHAL_USER_VECOFS)

#undef  XCHAL_KERNEL_VECTOR_VADDR
#define XCHAL_KERNEL_VECTOR_VADDR	XC_VADDR(XCHAL_KERNEL_VECOFS)

#undef  XCHAL_DOUBLEEXC_VECTOR_VADDR
#define XCHAL_DOUBLEEXC_VECTOR_VADDR	XC_VADDR(XCHAL_DOUBLEEXC_VECOFS)

#undef  XCHAL_WINDOW_VECTORS_VADDR
#define XCHAL_WINDOW_VECTORS_VADDR	XC_VADDR(XCHAL_WINDOW_OF4_VECOFS)

#undef  XCHAL_INTLEVEL2_VECTOR_VADDR
#define XCHAL_INTLEVEL2_VECTOR_VADDR	XC_VADDR(XCHAL_INTLEVEL2_VECOFS)

#undef  XCHAL_INTLEVEL3_VECTOR_VADDR
#define XCHAL_INTLEVEL3_VECTOR_VADDR	XC_VADDR(XCHAL_INTLEVEL3_VECOFS)

#undef  XCHAL_INTLEVEL4_VECTOR_VADDR
#define XCHAL_INTLEVEL4_VECTOR_VADDR	XC_VADDR(XCHAL_INTLEVEL4_VECOFS)

#undef  XCHAL_INTLEVEL5_VECTOR_VADDR
#define XCHAL_INTLEVEL5_VECTOR_VADDR	XC_VADDR(XCHAL_INTLEVEL5_VECOFS)

#undef  XCHAL_INTLEVEL6_VECTOR_VADDR
#define XCHAL_INTLEVEL6_VECTOR_VADDR	XC_VADDR(XCHAL_INTLEVEL6_VECOFS)

#undef  XCHAL_DEBUG_VECTOR_VADDR
#define XCHAL_DEBUG_VECTOR_VADDR	XC_VADDR(XCHAL_DEBUG_VECOFS)

#undef  XCHAL_NMI_VECTOR_VADDR
#define XCHAL_NMI_VECTOR_VADDR		XC_VADDR(XCHAL_NMI_VECOFS)

#undef  XCHAL_INTLEVEL7_VECTOR_VADDR
#define XCHAL_INTLEVEL7_VECTOR_VADDR	XC_VADDR(XCHAL_INTLEVEL7_VECOFS)

#else
/* MMV V1 or V2 */
#define VIRTUAL_MEMORY_ADDRESS  0xD0000000
#define KERNELOFFSET 		0xD0001000
#define LOAD_MEMORY_ADDRESS  	0xD0001000
#endif

#endif /* _XTENSA_ASM_CORE_H */
